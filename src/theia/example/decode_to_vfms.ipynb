{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from transformers import AutoModel\n",
    "from torchvision.io import read_video, write_video\n",
    "from theia.decoding import load_feature_stats, prepare_depth_decoder, prepare_mask_generator, decode_everything\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "theia_model = AutoModel.from_pretrained(\"theaiinstitute/theia-tiny-patch16-224-cddsv\", trust_remote_code=True)\n",
    "theia_model = theia_model.to(device)\n",
    "target_model_names = [\n",
    "    \"google/vit-huge-patch14-224-in21k\",\n",
    "    \"facebook/dinov2-large\",\n",
    "    \"openai/clip-vit-large-patch14\",\n",
    "    \"facebook/sam-vit-huge\",\n",
    "    \"LiheYoung/depth-anything-large-hf\",\n",
    "]\n",
    "feature_means, feature_vars = load_feature_stats(target_model_names, stat_file_root=\"../../../feature_stats\")\n",
    "\n",
    "mask_generator, sam_model = prepare_mask_generator(device)\n",
    "depth_anything_model_name = \"LiheYoung/depth-anything-large-hf\"\n",
    "depth_anything_decoder, _ = prepare_depth_decoder(depth_anything_model_name, device)\n",
    "\n",
    "example_video_path = \"../../../media/example_video_to_visualize.mp4\"\n",
    "video, _, _ = read_video(example_video_path, pts_unit=\"sec\", output_format=\"THWC\")\n",
    "video = video.numpy()\n",
    "images = [Image.fromarray(cv2.resize(im, (224, 224))) for im in video]\n",
    "\n",
    "theia_decode_results, gt_decode_results = decode_everything(\n",
    "    theia_model=theia_model,\n",
    "    feature_means=feature_means,\n",
    "    feature_vars=feature_vars,\n",
    "    images=images,\n",
    "    mask_generator=mask_generator,\n",
    "    sam_model=sam_model,\n",
    "    depth_anything_decoder=depth_anything_decoder,\n",
    "    pred_iou_thresh=0.5,\n",
    "    stability_score_thresh=0.7,\n",
    "    gt=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "vis_video = np.stack(\n",
    "    [np.vstack([tr, gtr]) for tr, gtr in zip(theia_decode_results, gt_decode_results, strict=False)]\n",
    ")\n",
    "vis_video = torch.from_numpy(vis_video * 255.0).to(torch.uint8)\n",
    "vis_save_path = \"./visualized.mp4\"\n",
    "write_video(vis_save_path, vis_video, fps=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
